name: Refactoring Opportunities Scanner

on:
  push:
    branches:
      - main
  # Run bi-weekly on the 1st and 15th at 10:00 AM UTC
  schedule:
    - cron: '0 10 1,15 * *'
  # Allow manual triggering
  workflow_dispatch:

# Ensure only one scan runs at a time
concurrency:
  group: refactoring-scanner
  cancel-in-progress: false

jobs:
  find-refactoring-opportunities:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      with:
        submodules: false

    - name: Install Python and dependencies
      run: |
        python3 -m pip install --upgrade pip
        pip3 install lizard

    - name: Create results directory
      run: |
        mkdir -p results

    - name: List Code Files
      run: |
        find magda/ tests/ \( -name "*.cpp" -o -name "*.hpp" -o -name "*.h" \) > file_list.txt
        echo "Found $(wc -l < file_list.txt) files to analyze"

    - name: Process Each File
      id: analyze_files
      run: |
        # Initialize summary file
        echo "=== Refactoring Analysis Summary ===" > refactoring-results-summary.txt
        echo "" >> refactoring-results-summary.txt
        
        TOTAL_FILES=$(wc -l < file_list.txt)
        COMPLEX_COUNT=0
        LARGE_FILE_COUNT=0
        COUPLING_COUNT=0
        
        echo "Processing $TOTAL_FILES files..." >> refactoring-results-summary.txt
        echo "" >> refactoring-results-summary.txt
        
        # Process each file
        while IFS= read -r file; do
          echo "Analyzing $file..."
          
          # Create sanitized filename for per-file results
          SAFE_FILENAME=$(echo "$file" | sed 's/[\/\.]/-/g')
          RESULT_FILE="results/refactoring-report-${SAFE_FILENAME}.txt"
          
          echo "=== Analysis Report for: $file ===" > "$RESULT_FILE"
          echo "" >> "$RESULT_FILE"
          
          # 1. Analyze complexity with lizard
          echo "--- Complexity Analysis ---" >> "$RESULT_FILE"
          LIZARD_OUTPUT=$(lizard "$file" -l cpp -C 10 2>&1 || echo "No high complexity functions found")
          echo "$LIZARD_OUTPUT" >> "$RESULT_FILE"
          
          # Check if file has high complexity
          if echo "$LIZARD_OUTPUT" | grep -q "^[[:space:]]*[0-9]"; then
            COMPLEX_COUNT=$((COMPLEX_COUNT + 1))
            echo "‚ö†Ô∏è  $file: High complexity detected" >> refactoring-results-summary.txt
          fi
          
          echo "" >> "$RESULT_FILE"
          
          # 2. Check file size
          LINES=$(wc -l < "$file")
          echo "--- File Size ---" >> "$RESULT_FILE"
          echo "Lines of code: $LINES" >> "$RESULT_FILE"
          
          if [ "$LINES" -gt 500 ]; then
            LARGE_FILE_COUNT=$((LARGE_FILE_COUNT + 1))
            echo "‚ö†Ô∏è  $file: Large file ($LINES lines)" >> refactoring-results-summary.txt
          fi
          
          echo "" >> "$RESULT_FILE"
          
          # 3. Check for tight coupling (internal includes)
          echo "--- Coupling Analysis ---" >> "$RESULT_FILE"
          INTERNAL_INCLUDES=$(grep -c "#include.*magda" "$file" 2>/dev/null || echo "0")
          echo "Internal includes: $INTERNAL_INCLUDES" >> "$RESULT_FILE"
          
          if [ "$INTERNAL_INCLUDES" -gt 10 ]; then
            COUPLING_COUNT=$((COUPLING_COUNT + 1))
            echo "‚ö†Ô∏è  $file: High coupling ($INTERNAL_INCLUDES internal includes)" >> refactoring-results-summary.txt
          fi
          
          echo "" >> "$RESULT_FILE"
          
          # 4. Check for magic numbers
          echo "--- Magic Numbers ---" >> "$RESULT_FILE"
          grep -n "[^a-zA-Z0-9_][0-9]\{2,\}[^a-zA-Z0-9_]" "$file" | \
            grep -v "\.0\|1000\|2000\|255" | head -10 >> "$RESULT_FILE" || echo "None found" >> "$RESULT_FILE"
          
          echo "" >> "$RESULT_FILE"
          
          # 5. For header files, check for god objects
          if [[ "$file" == *.hpp || "$file" == *.h ]]; then
            echo "--- Class Analysis ---" >> "$RESULT_FILE"
            CLASS_NAME=$(grep "^class\|^struct" "$file" | head -1 | awk '{print $2}' | sed 's/[:{]//g')
            if [ -n "$CLASS_NAME" ]; then
              METHOD_COUNT=$(awk '/^public:/,/^(private:|protected:)/ {if (/^\s*[a-zA-Z_][a-zA-Z0-9_]*\s*\(/) count++} END {print count+0}' "$file")
              echo "Class: $CLASS_NAME" >> "$RESULT_FILE"
              echo "Public methods: ~$METHOD_COUNT" >> "$RESULT_FILE"
              
              if [ "$METHOD_COUNT" -gt 20 ]; then
                echo "‚ö†Ô∏è  $file ($CLASS_NAME): Potential god object (~$METHOD_COUNT public methods)" >> refactoring-results-summary.txt
              fi
            fi
          fi
          
          echo "" >> "$RESULT_FILE"
          echo "File: $file processed" >> "$RESULT_FILE"
          
        done < file_list.txt
        
        # Add summary statistics
        echo "" >> refactoring-results-summary.txt
        echo "=== Summary Statistics ===" >> refactoring-results-summary.txt
        echo "Total files analyzed: $TOTAL_FILES" >> refactoring-results-summary.txt
        echo "Files with high complexity: $COMPLEX_COUNT" >> refactoring-results-summary.txt
        echo "Large files (>500 lines): $LARGE_FILE_COUNT" >> refactoring-results-summary.txt
        echo "Files with tight coupling (>10 includes): $COUPLING_COUNT" >> refactoring-results-summary.txt
        
        # Save metrics for later steps
        echo "complex_count=$COMPLEX_COUNT" >> $GITHUB_OUTPUT
        echo "large_file_count=$LARGE_FILE_COUNT" >> $GITHUB_OUTPUT
        echo "coupling_count=$COUPLING_COUNT" >> $GITHUB_OUTPUT

    - name: Find duplicate code patterns
      run: |
        echo "" >> refactoring-results-summary.txt
        echo "=== Potential Code Duplication ===" >> refactoring-results-summary.txt
        echo "Functions with similar names:" >> refactoring-results-summary.txt
        find magda/ tests/ \( -name "*.cpp" -o -name "*.hpp" -o -name "*.h" \) -exec grep -h "^[a-zA-Z_].*::" {} \; | \
          sort | uniq -c | sort -rn | head -20 >> refactoring-results-summary.txt || echo "None found" >> refactoring-results-summary.txt

    - name: Summarize Results
      run: |
        # Truncate summary to 65000 bytes to avoid GitHub API limits
        # Note: This truncates by bytes, not characters, to ensure we stay under the limit
        head -c 65000 refactoring-results-summary.txt > results/summary-truncated.txt || true
        
        # Also copy full summary
        cp refactoring-results-summary.txt results/summary-full.txt
        
        # Create a summary of per-file results
        echo "=== Per-File Analysis Reports ===" > results/file-index.txt
        echo "Individual file reports available in artifacts:" >> results/file-index.txt
        ls -1 results/refactoring-report-*.txt 2>/dev/null | while read -r report; do
          echo "  - $(basename "$report")" >> results/file-index.txt
        done || echo "No per-file reports generated" >> results/file-index.txt
        
        # Create a detailed findings report for GitHub issue (with size limit)
        echo "=== Detailed Per-File Findings ===" > results/detailed-findings.txt
        echo "" >> results/detailed-findings.txt
        
        # Only include files with issues (from the summary)
        grep "‚ö†Ô∏è" refactoring-results-summary.txt | while read -r line; do
          # Extract filename from the warning line
          FILE=$(echo "$line" | sed 's/‚ö†Ô∏è  \([^:]*\):.*/\1/')
          SAFE_FILENAME=$(echo "$FILE" | sed 's/[\/\.]/-/g')
          REPORT_FILE="results/refactoring-report-${SAFE_FILENAME}.txt"
          
          if [ -f "$REPORT_FILE" ]; then
            echo "<details>" >> results/detailed-findings.txt
            echo "<summary>üìÑ $FILE</summary>" >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
            echo '```' >> results/detailed-findings.txt
            cat "$REPORT_FILE" >> results/detailed-findings.txt
            echo '```' >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
            echo "</details>" >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
          fi
        done
        
        # Truncate detailed findings if too large (keep under 60KB for the issue body)
        head -c 60000 results/detailed-findings.txt > results/detailed-findings-truncated.txt || true

    - name: Upload Refactoring Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: refactoring-results
        path: results/
        retention-days: 30

    - name: Post Results on GitHub Issues
      if: steps.analyze_files.outputs.complex_count > 3
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Read the summary to get the list of files with issues
          const summary = fs.readFileSync('./refactoring-results-summary.txt', 'utf8');
          
          // Extract files with warnings (lines starting with ‚ö†Ô∏è)
          const warningLines = summary.split('\n').filter(line => line.startsWith('‚ö†Ô∏è'));
          
          console.log(`Found ${warningLines.length} files with refactoring opportunities`);
          
          // Process each file with issues
          for (const line of warningLines) {
            // Extract filename from the warning line: "‚ö†Ô∏è  path/to/file.cpp: issue description"
            const match = line.match(/‚ö†Ô∏è\s+([^:]+):\s*(.+)/);
            if (!match) {
              console.log(`Skipping malformed warning line: ${line}`);
              continue;
            }
            
            const filePath = match[1].trim();
            const issueDescription = match[2].trim();
            
            // Create sanitized filename for finding the report
            const safeFilename = filePath.replace(/[\/\.]/g, '-');
            const reportPath = `./results/refactoring-report-${safeFilename}.txt`;
            
            // Read the detailed report for this file
            let fileReport = '';
            try {
              fileReport = fs.readFileSync(reportPath, 'utf8');
            } catch (e) {
              console.log(`Could not read report for ${filePath}: ${e.message}`);
              fileReport = 'Detailed report not available.';
            }
            
            // Create issue title and body
            const issueTitle = `[Refactoring] ${filePath}`;
            const issueBody = `## Refactoring Opportunity: ${filePath}
          
          This issue was automatically created by the refactoring scanner workflow.
          
          ### Issue Detected
          ${issueDescription}
          
          ### Analysis Date
          ${new Date().toISOString().split('T')[0]}
          
          ### Detailed Analysis
          
          \`\`\`
          ${fileReport}
          \`\`\`
          
          ### Recommended Actions
          
          Based on the issue type:
          - **High Complexity**: Break down complex functions (cyclomatic complexity > 10) into smaller, more focused functions
          - **Large File**: Consider splitting file over 500 lines into smaller, focused modules
          - **High Coupling**: Review and reduce files with many internal dependencies (>10 includes)
          - **Magic Numbers**: Replace literal numbers with named constants
          - **God Object**: Consider splitting classes with 20+ methods into smaller, more focused classes
          
          ### Next Steps
          
          1. Review the detailed analysis above
          2. Plan refactoring approach
          3. Create a branch for the refactoring work
          4. Submit a PR with the improvements
          5. Close this issue when complete
          
          **Note**: This is an automated issue. Feel free to add comments, assign it, or close it if not applicable.
          `;
            
            // Check if an issue already exists for this file
            const searchQuery = `repo:${context.repo.owner}/${context.repo.repo} is:issue is:open label:refactoring label:automated "${issueTitle}"`;
            
            let existingIssues;
            try {
              const searchResult = await github.rest.search.issuesAndPullRequests({
                q: searchQuery
              });
              existingIssues = searchResult.data.items;
            } catch (e) {
              console.log(`Search failed: ${e.message}, will create new issue`);
              existingIssues = [];
            }
            
            if (existingIssues.length > 0) {
              // Issue already exists, add a comment with updated analysis
              const existingIssue = existingIssues[0];
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `## Updated Analysis - ${new Date().toISOString().split('T')[0]}\n\n${issueDescription}\n\n<details>\n<summary>Click to expand updated report</summary>\n\n\`\`\`\n${fileReport}\n\`\`\`\n\n</details>`
              });
              console.log(`Updated existing issue #${existingIssue.number} for ${filePath}`);
            } else {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['refactoring', 'automated', 'technical-debt']
              });
              console.log(`Created new issue for ${filePath}`);
            }
          }
          
          console.log('Finished processing all files with refactoring opportunities');

    - name: Summary
      run: |
        echo "## Refactoring Analysis Complete üîç" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Analysis Results" >> $GITHUB_STEP_SUMMARY
        echo "- **Files with high complexity**: ${{ steps.analyze_files.outputs.complex_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Large files (>500 lines)**: ${{ steps.analyze_files.outputs.large_file_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Files with tight coupling**: ${{ steps.analyze_files.outputs.coupling_count }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Review the full report in workflow artifacts for detailed per-file findings." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        COMPLEX_COUNT="${{ steps.analyze_files.outputs.complex_count }}"
        if [ "${COMPLEX_COUNT:-0}" -gt 3 ]; then
          echo "‚ö†Ô∏è **Action needed**: Separate GitHub issues created for each file with refactoring opportunities." >> $GITHUB_STEP_SUMMARY
        else
          echo "‚úÖ Code complexity is within acceptable limits." >> $GITHUB_STEP_SUMMARY
        fi
