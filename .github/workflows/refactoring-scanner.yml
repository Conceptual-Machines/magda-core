name: Refactoring Opportunities Scanner

on:
  workflow_dispatch:

# Ensure only one scan runs at a time
concurrency:
  group: refactoring-scanner
  cancel-in-progress: false

jobs:
  find-refactoring-opportunities:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read

    steps:
    - name: Checkout Code
      uses: actions/checkout@v6
      with:
        submodules: false

    - name: Install Python and dependencies
      run: |
        python3 -m pip install --upgrade pip
        pip3 install lizard requests

    - name: Create results directory
      run: |
        mkdir -p results

    - name: List Code Files
      run: |
        # Only scan .cpp source files over 300 lines ‚Äî skip headers, tests, and small files
        find magda/ \( -name "*.cpp" \) > file_candidates.txt
        > file_list.txt
        while IFS= read -r file; do
          LINES=$(wc -l < "$file")
          if [ "$LINES" -gt 300 ]; then
            echo "$file" >> file_list.txt
          fi
        done < file_candidates.txt
        echo "Found $(wc -l < file_list.txt) files to analyze (filtered from $(wc -l < file_candidates.txt) candidates)"

    - name: Process Each File
      id: analyze_files
      run: |
        # Initialize summary file
        echo "=== Refactoring Analysis Summary ===" > refactoring-results-summary.txt
        echo "" >> refactoring-results-summary.txt

        TOTAL_FILES=$(wc -l < file_list.txt)
        COMPLEX_COUNT=0
        LARGE_FILE_COUNT=0
        COUPLING_COUNT=0

        echo "Processing $TOTAL_FILES files..." >> refactoring-results-summary.txt
        echo "" >> refactoring-results-summary.txt

        # Process each file
        while IFS= read -r file; do
          echo "Analyzing $file..."

          # Create sanitized filename for per-file results
          SAFE_FILENAME=$(echo "$file" | sed 's/[\/\.]/-/g')
          RESULT_FILE="results/refactoring-report-${SAFE_FILENAME}.txt"

          echo "=== Analysis Report for: $file ===" > "$RESULT_FILE"
          echo "" >> "$RESULT_FILE"

          # 1. Analyze complexity with lizard
          echo "--- Complexity Analysis ---" >> "$RESULT_FILE"
          LIZARD_OUTPUT=$(lizard "$file" -l cpp -C 15 2>&1 || echo "No high complexity functions found")
          echo "$LIZARD_OUTPUT" >> "$RESULT_FILE"

          # Check if file has high complexity
          if echo "$LIZARD_OUTPUT" | grep -q "^[[:space:]]*[0-9]"; then
            COMPLEX_COUNT=$((COMPLEX_COUNT + 1))
            echo "‚ö†Ô∏è  $file: High complexity detected" >> refactoring-results-summary.txt
          fi

          echo "" >> "$RESULT_FILE"

          # 2. Check file size
          LINES=$(wc -l < "$file")
          echo "--- File Size ---" >> "$RESULT_FILE"
          echo "Lines of code: $LINES" >> "$RESULT_FILE"

          if [ "$LINES" -gt 800 ]; then
            LARGE_FILE_COUNT=$((LARGE_FILE_COUNT + 1))
            echo "‚ö†Ô∏è  $file: Large file ($LINES lines)" >> refactoring-results-summary.txt
          fi

          echo "" >> "$RESULT_FILE"

          # 3. Check for tight coupling (internal includes)
          echo "--- Coupling Analysis ---" >> "$RESULT_FILE"
          INTERNAL_INCLUDES=$(grep -c "#include.*magda" "$file" 2>/dev/null || echo "0")
          echo "Internal includes: $INTERNAL_INCLUDES" >> "$RESULT_FILE"

          if [ "$INTERNAL_INCLUDES" -gt 10 ]; then
            COUPLING_COUNT=$((COUPLING_COUNT + 1))
            echo "‚ö†Ô∏è  $file: High coupling ($INTERNAL_INCLUDES internal includes)" >> refactoring-results-summary.txt
          fi

          echo "" >> "$RESULT_FILE"

          # 4. (Magic number scanning removed ‚Äî produces too many false positives)

          # 5. (Header-only God Object scanning removed ‚Äî headers are excluded from file list)

          echo "" >> "$RESULT_FILE"
          echo "File: $file processed" >> "$RESULT_FILE"

        done < file_list.txt

        # Add summary statistics
        echo "" >> refactoring-results-summary.txt
        echo "=== Summary Statistics ===" >> refactoring-results-summary.txt
        echo "Total files analyzed: $TOTAL_FILES" >> refactoring-results-summary.txt
        echo "Files with high complexity: $COMPLEX_COUNT" >> refactoring-results-summary.txt
        echo "Large files (>800 lines): $LARGE_FILE_COUNT" >> refactoring-results-summary.txt
        echo "Files with tight coupling (>10 includes): $COUPLING_COUNT" >> refactoring-results-summary.txt

        # Save metrics for later steps
        echo "complex_count=$COMPLEX_COUNT" >> $GITHUB_OUTPUT
        echo "large_file_count=$LARGE_FILE_COUNT" >> $GITHUB_OUTPUT
        echo "coupling_count=$COUPLING_COUNT" >> $GITHUB_OUTPUT

    - name: Find duplicate code patterns
      run: |
        echo "" >> refactoring-results-summary.txt
        echo "=== Potential Code Duplication ===" >> refactoring-results-summary.txt
        echo "Functions with similar names:" >> refactoring-results-summary.txt
        find magda/ tests/ \( -name "*.cpp" -o -name "*.hpp" -o -name "*.h" \) -exec grep -h "^[a-zA-Z_].*::" {} \; | \
          sort | uniq -c | sort -rn | head -20 >> refactoring-results-summary.txt || echo "None found" >> refactoring-results-summary.txt

    - name: Summarize Results
      run: |
        # Truncate summary to 65000 bytes to avoid GitHub API limits
        # Note: This truncates by bytes, not characters, to ensure we stay under the limit
        head -c 65000 refactoring-results-summary.txt > results/summary-truncated.txt || true

        # Also copy full summary
        cp refactoring-results-summary.txt results/summary-full.txt

        # Create a summary of per-file results
        echo "=== Per-File Analysis Reports ===" > results/file-index.txt
        echo "Individual file reports available in artifacts:" >> results/file-index.txt
        ls -1 results/refactoring-report-*.txt 2>/dev/null | while read -r report; do
          echo "  - $(basename "$report")" >> results/file-index.txt
        done || echo "No per-file reports generated" >> results/file-index.txt

        # Create a detailed findings report for GitHub issue (with size limit)
        echo "=== Detailed Per-File Findings ===" > results/detailed-findings.txt
        echo "" >> results/detailed-findings.txt

        # Only include files with issues (from the summary)
        grep "‚ö†Ô∏è" refactoring-results-summary.txt | while read -r line; do
          # Extract filename from the warning line
          FILE=$(echo "$line" | sed 's/‚ö†Ô∏è  \([^:]*\):.*/\1/')
          SAFE_FILENAME=$(echo "$FILE" | sed 's/[\/\.]/-/g')
          REPORT_FILE="results/refactoring-report-${SAFE_FILENAME}.txt"

          if [ -f "$REPORT_FILE" ]; then
            echo "<details>" >> results/detailed-findings.txt
            echo "<summary>üìÑ $FILE</summary>" >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
            echo '```' >> results/detailed-findings.txt
            cat "$REPORT_FILE" >> results/detailed-findings.txt
            echo '```' >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
            echo "</details>" >> results/detailed-findings.txt
            echo "" >> results/detailed-findings.txt
          fi
        done

        # Truncate detailed findings if too large (keep under 60KB for the issue body)
        head -c 60000 results/detailed-findings.txt > results/detailed-findings-truncated.txt || true

    - name: Upload Refactoring Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: refactoring-results
        path: results/
        retention-days: 30

    - name: Post Results on GitHub Issues
      if: steps.analyze_files.outputs.complex_count > 3
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python3 scripts/create_refactoring_issues.py \
          --summary ./refactoring-results-summary.txt \
          --results-dir ./results \
          --delay 2.5 \
          --max-retries 5

    - name: Summary
      run: |
        echo "## Refactoring Analysis Complete üîç" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Analysis Results" >> $GITHUB_STEP_SUMMARY
        echo "- **Files with high complexity**: ${{ steps.analyze_files.outputs.complex_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Large files (>800 lines)**: ${{ steps.analyze_files.outputs.large_file_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Files with tight coupling**: ${{ steps.analyze_files.outputs.coupling_count }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Review the full report in workflow artifacts for detailed per-file findings." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        COMPLEX_COUNT="${{ steps.analyze_files.outputs.complex_count }}"
        if [ "${COMPLEX_COUNT:-0}" -gt 3 ]; then
          echo "‚ö†Ô∏è **Action needed**: Separate GitHub issues created for each file with refactoring opportunities." >> $GITHUB_STEP_SUMMARY
        else
          echo "‚úÖ Code complexity is within acceptable limits." >> $GITHUB_STEP_SUMMARY
        fi
